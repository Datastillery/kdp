---
apiVersion: v1
kind: ConfigMap
metadata:
  name: hive-site
  labels:
    app: hive-server
data:
  hive-site.xml: |-
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hive-metastore:9083</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://postgres/metastore</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>password123</value>
      </property>
      <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>true</value>
      </property>
      <property>
        <name>datanucleus.fixedDatastore</name>
        <value>true</value>
      </property>
      <property>
        <name>datanucleus.autoCreateTables</name>
        <value>True</value>
      </property>
      <property>
        <name>hive.execution.engine</name>
        <value>spark</value>
      </property>
      <property>
        <name>spark.master</name>
        <value>k8s://https://kubernetes.default.svc.cluster.local:443</value>
      </property>
      <property>
        <name>spark.eventLog.enabled</name>
        <value>true</value>
      </property>
      <property>
        <name>spark.eventLog.dir</name>
        <value>/dev/stdout</value>
      </property>
      <property>
        <name>spark.executor.memory</name>
        <value>1g</value>
      </property>
      <property>
        <name>spark.serializer</name>
        <value>org.apache.spark.serializer.KryoSerializer</value>
      </property>
      <property>
        <name>spark.kubernetes.namespace</name>
        <value>default</value>
      </property>
      <property>
        <name>spark.kubernetes.container.image</name>
        <value>gcr.io/cloud-solutions-images/spark:v2.3.0-gcs</value>
      </property>
      <property>
        <name>spark.kubernetes.container.image.pullPolicy</name>
        <value>IfNotPresent</value>
      </property>
      <property>
        <name>spark.executor.instances</name>
        <value>2</value>
      </property>
      <property>
        <name>spark.kubernetes.allocation.batch.size</name>
        <value>2</value>
      </property>
      <property>
        <name>spark.kubernetes.allocation.batch.delay</name>
        <value>10s</value>
      </property>
      <property>
        <name>spark.kubernetes.driver.label.seatOf</name>
        <value>pants</value>
      </property>
      <property>
        <name>spark.kubernetes.executor.label.seatOf</name>
        <value>pants</value>
      </property>
      <property>
        <name>spark.app.name</name>
        <value>de-doop</value>
      </property>
      <property>
        <name>spark.submit.deployMode</name>
        <value>cluster</value>
      </property>
    </configuration>
